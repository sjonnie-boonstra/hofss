{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect all data and put them in a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "results_path = \"/home/boonstra/xin_results_24_3(2)\"\n",
    "\n",
    "data_frames = []\n",
    "for filename in os.listdir(results_path):\n",
    "    seed, extension = os.path.splitext(filename)\n",
    "    if extension.lower() != \".csv\":\n",
    "        continue\n",
    "    filepath = os.path.join(results_path, filename)\n",
    "    df = pd.read_csv(filepath, header=0)\n",
    "    df[\"seed\"] = seed\n",
    "    data_frames.append(df)\n",
    "\n",
    "all_data = pd.concat(data_frames)\n",
    "\n",
    "all_data.columns\n",
    "from hofss import Task, TaskType, Factor, Scenario\n",
    "\n",
    "hofs = Factor.parse_from_file(\"data/hofs_frequencies_and_multipliers.csv\")\n",
    "task_types = TaskType.parse_from_file(\"data/gtt_nhep_hofs.csv\", hofs)\n",
    "scenarios = Scenario.parse_from_file(\"data/scenarios.csv\")\n",
    "tasks = Task.parse_from_file(\"data/tasks.csv\", task_types, scenarios)\n",
    "\n",
    "typed_data = []\n",
    "all_data[\"task_type\"] = None\n",
    "for task, group_data in all_data.groupby(\"task\"):\n",
    "    task_instance: Task = next(filter(lambda x: task == x.name, tasks), None)\n",
    "    group_data[\"task_type\"] = task_instance.task_type.name\n",
    "    typed_data.append(group_data)\n",
    "all_data = pd.concat(typed_data)\n",
    "all_data.index = range(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scenario_data = all_data[all_data[\"scenario\"].notna()].copy()\n",
    "previous_failure_probabilities = all_data.iloc[scenario_data.index - 1][\"total\"]\n",
    "scenario_data[\"failure_probability_change\"] = scenario_data[\"total\"].values / previous_failure_probabilities.values\n",
    "# scenario_data.dropna(inplace=True, subset=[\"failure_probability_change\"])\n",
    "scenario_data = scenario_data[~scenario_data[\"failure_probability_change\"].isin([np.nan, np.inf, -np.inf])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.axes._axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counter = 0\n",
    "p = None\n",
    "fig, axs = plt.subplots(len(scenario_data[\"task\"].unique()), sharex=True)\n",
    "scale_factor = 3\n",
    "fig.set_size_inches(w=scale_factor*80/25.4, h=scale_factor*80/25.4)\n",
    "ax: Axes\n",
    "for (i, ax), (task, group_data) in zip(enumerate(axs), scenario_data.groupby(\"task\")):\n",
    "    log_values = [np.log10(value) for value in group_data[\"failure_probability_change\"] if value >= 2e-7]\n",
    "    ax.hist(log_values,linewidth=0.5, edgecolor=\"black\", bins=np.arange(-3.5,5.0,0.1))\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.set_ylabel(task, rotation=\"horizontal\")\n",
    "    ax.tick_params(\n",
    "        \"both\", bottom=True, left=False, top=False, labelbottom=i == len(axs) - 1, labelleft=False\n",
    "    )\n",
    "    ax.axvline(0, color=\"black\")\n",
    "\n",
    "    # print(task, len(group_data), group_data[\"failure_probability_change\"].mean(), group_data[\"failure_probability_change\"].std())\n",
    "    counter += 1\n",
    "    axs[i] = ax\n",
    "    # if counter == 3:\n",
    "    #     break \n",
    "\n",
    "fig.tight_layout()\n",
    "# list(p[\"failure_probability_change\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmean(a):\n",
    "    return np.prod(a)**(1/len(a))\n",
    "\n",
    "def gmean_contributions(a: pd.Series):\n",
    "    # remove nan_values\n",
    "    b = a.dropna()\n",
    "\n",
    "    contributors = []\n",
    "    for index in b.index:\n",
    "        contributors.append(gmean(b.values) / gmean(b.drop(index)))\n",
    "\n",
    "    # return new series\n",
    "    return pd.Series({k.replace(\"multiplier\", \"contribution\"): v for k, v in zip(b.index, contributors)})\n",
    "\n",
    "rows = []\n",
    "multiplier_columns = [c for c in scenario_data.columns if \"multiplier\" in c]\n",
    "count = 0\n",
    "for row_index, row in scenario_data.iterrows():\n",
    "    rows.append(pd.concat([row, gmean_contributions(row[multiplier_columns])]))\n",
    "    count += 1\n",
    "\n",
    "enriched_data = pd.concat(rows, axis=1).T\n",
    "improvement_data = enriched_data[enriched_data[\"failure_probability_change\"] <= 1.0]\n",
    "degradation_data = enriched_data[enriched_data[\"failure_probability_change\"] > 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type_order = [tt.name for tt in task_types]\n",
    "factors = [f\"F{i}\" for i in range(1,15)]\n",
    "\n",
    "plot_values = []\n",
    "plot_labels = []\n",
    "for task_type in task_type_order:\n",
    "    task_type_values = []\n",
    "    task_type_labels = []\n",
    "    subset = enriched_data[enriched_data[\"task_type\"] == task_type]\n",
    "    probabilities = np.array(subset[\"failure_probability_change\"].values, dtype=np.float64)\n",
    "\n",
    "    for factor in factors:\n",
    "        contributions = np.array(subset[f\"{factor}_contribution\"].values, dtype=np.float64)\n",
    "        task_type_values.append(np.log10(np.mean(probabilities**contributions)))\n",
    "        task_type_labels.append(np.mean(contributions))\n",
    "    plot_values.append(task_type_values)\n",
    "    plot_labels.append(task_type_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "scale_factor = 3.0\n",
    "fig.set_size_inches(w=80*scale_factor/25.4,h=60*scale_factor/25.4)\n",
    "im = ax.imshow(plot_values,cmap=cm.get_cmap(\"OrRd\"))\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(factors)), labels=[f.description for f in hofs])\n",
    "ax.set_yticks(np.arange(len(task_type_order)), labels=[tt.description for tt in task_types])\n",
    "ax.set_xlabel(\"Factor\")\n",
    "ax.set_ylabel(\"Task type\")\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(task_type_order)):\n",
    "    for j in range(len(factors)):\n",
    "        if np.isnan(plot_values[i][j]):\n",
    "            continue\n",
    "        text = ax.text(j, i, round(plot_values[i][j], 1), ha=\"center\", va=\"center\")\n",
    "\n",
    "ax.set_title(\"Effect on failure probability\")\n",
    "shift=0.05\n",
    "fig.tight_layout(rect=(shift,0,1+shift,1))\n",
    "fig.savefig(\"sensitivity.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
