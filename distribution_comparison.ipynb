{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect all data and put them in a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "checked_path = \"/home/boonstra/24_04_11_with_checks\"\n",
    "unchecked_path = \"/home/boonstra/24_04_11_without_checks\"\n",
    "\n",
    "def parse_data(data_path):\n",
    "    data_frames = []\n",
    "    for filename in os.listdir(checked_path):\n",
    "        seed, extension = os.path.splitext(filename)\n",
    "        if extension.lower() != \".csv\":\n",
    "            continue\n",
    "        filepath = os.path.join(data_path, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, header=0)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        df[\"seed\"] = seed\n",
    "        data_frames.append(df)\n",
    "\n",
    "    all_data = pd.concat(data_frames)\n",
    "    all_data.index = range(len(all_data))\n",
    "    return all_data\n",
    "\n",
    "checked_data = parse_data(checked_path)\n",
    "unchecked_data = parse_data(unchecked_path)\n",
    "\n",
    "checked_final_task_data = checked_data[checked_data[\"task\"] == \"C8\"]\n",
    "unchecked_final_task_data = unchecked_data[unchecked_data[\"task\"] == \"C8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(len(checked_data[checked_data[\"scenario\"].notna()]))\n",
    "print(len(checked_data[np.logical_and(checked_data[\"scenario\"].notna(), checked_data[\"error_corrected\"] != True)]))\n",
    "print(len(unchecked_data[unchecked_data[\"scenario\"].notna()]))\n",
    "print(len(unchecked_data[np.logical_and(unchecked_data[\"scenario\"].notna(), unchecked_data[\"error_corrected\"] != True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def filter_error_included_simulations(data):\n",
    "    error_included_data = []\n",
    "    for _, data in data.groupby(\"seed\"):\n",
    "        if any(np.logical_and(data[\"scenario\"].notna(), data[\"error_corrected\"] != True)):\n",
    "\n",
    "            error_included_data.append(data)\n",
    "    error_included_data = pd.concat(error_included_data)\n",
    "\n",
    "    return error_included_data\n",
    "\n",
    "checked_error_included_data = filter_error_included_simulations(checked_data)\n",
    "unchecked_error_included_data = filter_error_included_simulations(unchecked_data)\n",
    "\n",
    "checked_final_task_error_included_data = checked_error_included_data[checked_error_included_data[\"task\"] == \"C8\"]\n",
    "unchecked_final_task_error_included_data = unchecked_error_included_data[unchecked_error_included_data[\"task\"] == \"C8\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def obtain_log_values(data):\n",
    "    return [np.log10(v) for v in data[\"total\"] if v >= 2e-7]\n",
    "\n",
    "checked_log_values = obtain_log_values(checked_final_task_data)\n",
    "checked_error_included_log_values = obtain_log_values(checked_final_task_error_included_data)\n",
    "unchecked_log_values = obtain_log_values(unchecked_final_task_data)\n",
    "unchecked_error_included_log_values = obtain_log_values(unchecked_final_task_error_included_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from: https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from scipy.stats._continuous_distns import _distn_names\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "def best_fit_distribution(data, bins=200):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x  = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Best holders\n",
    "    best_distributions = []\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for ii, distribution in enumerate([d for d in _distn_names if not d in ['levy_stable', 'studentized_range']]):\n",
    "\n",
    "        distribution = getattr(st, distribution)\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                \n",
    "                # fit dist to data\n",
    "                params = distribution.fit(data)\n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "                \n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                mse = np.mean(np.power(y - pdf, 2.0))\n",
    "                \n",
    "                # identify if this distribution is better\n",
    "                best_distributions.append((distribution, params, mse))\n",
    "        \n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    return sorted(best_distributions, key=lambda x:x[2])\n",
    "\n",
    "best_fits_checked = best_fit_distribution(checked_log_values)\n",
    "best_fits_checked_error_included = best_fit_distribution(checked_error_included_log_values)\n",
    "best_fits_unchecked = best_fit_distribution(unchecked_log_values)\n",
    "best_fits_unchecked_error_included = best_fit_distribution(unchecked_error_included_log_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_top_5(best_fits, header):\n",
    "\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for i in range(5):\n",
    "        fit = best_fits[i]\n",
    "        print(f\"{fit[0].name}: {fit[2]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print_top_5(best_fits_checked, \"checked_all\")\n",
    "print_top_5(best_fits_checked_error_included, \"checked_error_incl\")\n",
    "\n",
    "print_top_5(best_fits_unchecked, \"unchecked_all\")\n",
    "print_top_5(best_fits_unchecked_error_included, \"unchecked_error_incl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from: https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python\n",
    "\n",
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "best_fits_checked[0][0].name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.axes._axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import laplace\n",
    "\n",
    "mean=0.000161\n",
    "fig, axs = plt.subplots(1,2)\n",
    "scale_factor = 3\n",
    "n_bins=50\n",
    "fig.set_size_inches(w=scale_factor*80/25.4, h=scale_factor*40/25.4)\n",
    "\n",
    "for data_label, y_pos, color in zip([\"unchecked\", \"checked\"], [0.95,0.9], [\"C0\", \"C1\"]):\n",
    "    x_pos = 0.02 if data_label == \"checked\" else 0.5\n",
    "    data = globals()[f\"{data_label}_final_task_data\"]\n",
    "    log_values = globals()[f\"{data_label}_log_values\"]\n",
    "    n_values = len(data)\n",
    "    n_failure_free = n_values - len(globals()[f\"{data_label}_final_task_error_included_data\"])\n",
    "    # print(len(globals()[f\"{data_label}_final_task_error_included_data\"]))\n",
    "    n_zero_values = n_values - len(log_values)\n",
    "\n",
    "\n",
    "    lap_loc = np.log10(mean)\n",
    "    lap_pairs = sorted([(abs(v - lap_loc), v) for v in log_values], key=lambda x: x[0])\n",
    "    lap_pairs = lap_pairs[n_failure_free:]\n",
    "    lap_differences, lap_values = zip(*lap_pairs)\n",
    "    lap_scale = np.mean(lap_differences)\n",
    "\n",
    "    ax: Axes = axs[0]\n",
    "    n, bins, patches = ax.hist(log_values, bins=n_bins, linewidth=0.5, edgecolor=\"black\")\n",
    "    bin_width = bins[1] - bins[0]\n",
    "    lap_loc, lap_scale = laplace.fit(lap_values)\n",
    "    lap_x = np.arange(-7, 0.01, 0.01)\n",
    "    lap_y = laplace.pdf(lap_x, loc=lap_loc, scale=lap_scale) * len(lap_values) * bin_width\n",
    "    # ax.plot(lap_x, lap_y, color=\"red\", linewidth=1.0)\n",
    "    ax.set_title(\"all results\")\n",
    "    ax.set_xlabel(\"Failure probability [-]\")\n",
    "    ax.set_ylabel(\"Frequency [%]\")\n",
    "    axs[0].text(x=x_pos, y= 0.95, s=f\"{data_label}\",transform=ax.transAxes, weight=\"bold\", color=color)\n",
    "    axs[0].text(x=x_pos, y= 0.90, s=f\"{data_label} peak: {round(max(n)/1000,2)}%\",transform=ax.transAxes, color=color)\n",
    "    axs[0].text(x=x_pos, y= 0.85, s=f\"zero-probability: {round(n_zero_values/1000,1)}%\",transform=ax.transAxes, color=color)\n",
    "    axs[0].text(x=x_pos, y= 0.8, s=f\"error-free: {round(n_failure_free/1000,1)}%\",transform=ax.transAxes, color=color)\n",
    "    axs[0] = ax\n",
    "\n",
    "    # plot zoomed in figure on degradations\n",
    "    ax: Axes = axs[1]\n",
    "    n, bins, patches = ax.hist(log_values, bins=bins, linewidth=0.5, edgecolor=\"black\")\n",
    "    # ax.plot(lap_x, lap_y, color=\"red\", linewidth=1.0)\n",
    "    ax.set_title(\"degradations\")\n",
    "    ax.set_xlabel(\"Failure probability [-]\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    axs[1] = ax\n",
    "\n",
    "\n",
    "y_lims = [5,2.0]\n",
    "y_tick_increment=[1.0,0.5]\n",
    "x_lims = [-7, -3.5]\n",
    "for i in [0,1]:\n",
    "    ax: Axes = axs[i]\n",
    "    if y_lims[i] is None:\n",
    "        _, y_max = ax.get_ylim()\n",
    "    else:\n",
    "        y_max = y_lims[i] * n_values / 100\n",
    "    x_min = x_lims[i]\n",
    "    ax.set_ylim(0,y_max)\n",
    "    ax.set_xlim(x_min, 0)\n",
    "    axs[i] = ax\n",
    "\n",
    "fig.suptitle(\"Failure probabilities after simulations\")\n",
    "# fig.tight_layout()\n",
    "for i in [0,1]:\n",
    "    ax: Axes = axs[i]\n",
    "\n",
    "    if y_lims[i] is None:\n",
    "        _, y_max = ax.get_ylim()\n",
    "        y_max /= n_values/100\n",
    "    else:\n",
    "        y_max = y_lims[i]\n",
    "    x_min = x_lims[i]\n",
    "\n",
    "    \n",
    "    x_tick_positions = ax.get_xticks()\n",
    "    x_tick_labels = [\"$\\mathregular{10^{%s}}$\" %(item,) for item in x_tick_positions]\n",
    "    ax.set_xticks(x_tick_positions, x_tick_labels)\n",
    "\n",
    "    y_tick_values = np.arange(0, y_max + y_tick_increment[i], y_tick_increment[i])\n",
    "    y_tick_positions = y_tick_values * n_values / 100\n",
    "    y_tick_labels = [f\"{round(item,1)}\" for item in y_tick_values]\n",
    "    ax.set_yticks(y_tick_positions, y_tick_labels)\n",
    "    axs[i] = ax\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"probabilities_after_simulations.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_histogram(\n",
    "    data=final_task_data['total'], bins=50,\n",
    "    n_failure_free=len(final_task_data) - len(final_task_error_included_data),\n",
    "    figure_name=\"probabilities_after_simulation_with_checks\",\n",
    "    y_lims=[4, 1.2],y_tick_increment=[0.5,0.1],\n",
    "    title=\"Failure probabilities after simulations with checking procedure\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "scale_factor = 3\n",
    "fig.set_size_inches(w=scale_factor*40/25.4, h=scale_factor*40/25.4)\n",
    "log_values = [np.log10(value) for value in final_task_data[\"total\"] if value >= 2e-7]\n",
    "n, bins, patches = ax.hist(log_values, bins=50, linewidth=0.5, edgecolor=\"black\")\n",
    "ax.set_title(\"Failure probabilities after simulations\\nwithout check\")\n",
    "ax.set_xlabel(\"Failure probability [-]\")\n",
    "ax.set_ylabel(\"Frequency [%]\")\n",
    "\n",
    "fig.tight_layout()\n",
    "x_ticks = [\"$\\mathregular{10^{%s}}$\" %(item.get_text(),) for item in ax.get_xticklabels()]\n",
    "ax.set_xticklabels(x_ticks)\n",
    "y_ticks = [f\"{round(float(item.get_text())/1000,2)}\" for item in ax.get_yticklabels()]\n",
    "ax.set_yticklabels(y_ticks)\n",
    "fig.savefig(\"probabilities_after_simulation_without_checks_no_zoom.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
